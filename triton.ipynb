{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "import paddle\n",
    "\n",
    "@triton.jit\n",
    "def gemm_kernel(\n",
    "    # 指针参数\n",
    "    a_ptr,                                # 激活矩阵指针 (float16)\n",
    "    w_ptr,                               # 权重矩阵指针 (int4)\n",
    "    output_ptr,                          # 输出矩阵指针 (float32)\n",
    "    # 矩阵维度参数\n",
    "    M, N, K,\n",
    "    # 步长参数\n",
    "    stride_am, stride_ak,                # 激活矩阵的步长\n",
    "    stride_wk, stride_wn,                # 权重矩阵的步长\n",
    "    stride_om, stride_on,                # 输出矩阵的步长\n",
    "    # 块大小参数\n",
    "    BLOCK_M: tl.constexpr,\n",
    "    BLOCK_N: tl.constexpr,\n",
    "    BLOCK_K: tl.constexpr,\n",
    "    # group size参数\n",
    "    GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    \"\"\"\n",
    "    计算 GEMM: output = activation @ weight.T\n",
    "    参数:\n",
    "        a_ptr: 激活矩阵指针 (M, K)，float16类型\n",
    "        w_ptr: 权重矩阵指针 (N, K)，int4类型\n",
    "        output_ptr: 输出矩阵指针 (M, N)，float32类型\n",
    "    \"\"\"\n",
    "    # -----------------------------------------------------------\n",
    "    # 计算程序ID\n",
    "    pid = tl.program_id(0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 计算当前块的偏移\n",
    "    offs_am = (pid_m * BLOCK_M + tl.arange(0, BLOCK_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_N + tl.arange(0, BLOCK_N)) % N\n",
    "    offs_k = tl.arange(0, BLOCK_K)\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 创建指针\n",
    "    a_ptrs = a_ptr + offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak\n",
    "    w_ptrs = w_ptr + offs_k[:, None] * stride_wk + offs_bn[None, :] * stride_wn\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 初始化累加器\n",
    "    accumulator = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 主循环\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_K)):\n",
    "        # 加载激活值\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_K, other=0.0)\n",
    "        w = tl.load(w_ptrs, mask=offs_k[:, None] < K - k * BLOCK_K, other=0.0)\n",
    "        \n",
    "        # 累加结果\n",
    "        accumulator += tl.dot(a.to(tl.float32), w.to(tl.float32))\n",
    "        \n",
    "        # 更新指针\n",
    "        a_ptrs += BLOCK_K * stride_ak\n",
    "        w_ptrs += BLOCK_K * stride_wk\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 写回结果\n",
    "    offs_om = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
    "    offs_on = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
    "    out_ptrs = output_ptr + offs_om[:, None] * stride_om + offs_on[None, :] * stride_on\n",
    "    o_mask = (offs_om[:, None] < M) & (offs_on[None, :] < N)\n",
    "    tl.store(out_ptrs, accumulator, mask=o_mask)\n",
    "\n",
    "# 包装函数\n",
    "def gemm(activation, weight):\n",
    "    \"\"\"\n",
    "    执行GEMM运算\n",
    "    参数:\n",
    "        activation: 激活矩阵 (M, K)，float16类型\n",
    "        weight: 权重矩阵 (N, K)，int4类型（以uint8打包存储）\n",
    "    返回:\n",
    "        output: 输出矩阵 (M, N)，float32类型\n",
    "    \"\"\"\n",
    "    M, K = activation.shape\n",
    "    #N, K_ = weight.shape\n",
    "    #assert K == K_, f\"维度不匹配: activation.K={K} != weight.K={K_}\"\n",
    "    \n",
    "    # 输出分配\n",
    "    output = paddle.zeros((M, N), dtype='float32')\n",
    "    \n",
    "    # 计算 grid 和 block 大小\n",
    "    BLOCK_M = 16\n",
    "    BLOCK_N = 16\n",
    "    BLOCK_K = 32\n",
    "    GROUP_SIZE_M = 8\n",
    "    \n",
    "    grid = lambda META: (\n",
    "        triton.cdiv(M, BLOCK_M) * triton.cdiv(N, BLOCK_N),\n",
    "    )\n",
    "    \n",
    "    gemm_kernel[grid](\n",
    "        activation, weight, output,\n",
    "        M, N, K,\n",
    "        activation.strides[0], activation.strides[1],\n",
    "        weight.strides[0], weight.strides[1],\n",
    "        output.strides[0], output.strides[1],\n",
    "        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K,\n",
    "        GROUP_SIZE_M=GROUP_SIZE_M,\n",
    "    )\n",
    "    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "import paddle\n",
    "\n",
    "@triton.jit\n",
    "def wint2_gemm_kernel(\n",
    "    # 指针参数\n",
    "    a_ptr,                                # 激活矩阵指针 (float16)\n",
    "    w_ptr,                               # 权重矩阵指针 (int4)\n",
    "    output_ptr,                          # 输出矩阵指针 (float32)\n",
    "    scale,\n",
    "    # 矩阵维度参数\n",
    "    M, N, K,\n",
    "    # 步长参数\n",
    "    stride_am, stride_ak,                # 激活矩阵的步长\n",
    "    stride_wk, stride_wn,                # 权重矩阵的步长\n",
    "    stride_om, stride_on,                # 输出矩阵的步长\n",
    "    # 块大小参数\n",
    "    BLOCK_M: tl.constexpr,\n",
    "    BLOCK_N: tl.constexpr,\n",
    "    BLOCK_K: tl.constexpr,\n",
    "    W_BLOCK_K: tl.constexpr,\n",
    "    # group size参数\n",
    "    GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    \"\"\"\n",
    "    计算 GEMM: output = activation @ weight.T\n",
    "    参数:\n",
    "        a_ptr: 激活矩阵指针 (M, K)，float16类型\n",
    "        w_ptr: 权重矩阵指针 (N, K)，int4类型\n",
    "        output_ptr: 输出矩阵指针 (M, N)，float32类型\n",
    "    \"\"\"\n",
    "    # -----------------------------------------------------------\n",
    "    # 计算程序ID\n",
    "    pid = tl.program_id(0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 计算当前块的偏移\n",
    "    offs_am = (pid_m * BLOCK_M + tl.arange(0, BLOCK_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_N + tl.arange(0, BLOCK_N)) % N\n",
    "    a_offs_k = tl.arange(0, BLOCK_K)\n",
    "    w_offs_k = tl.arange(0, W_BLOCK_K)\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 创建指针\n",
    "    a_ptrs = a_ptr + offs_am[:, None] * stride_am + a_offs_k[None, :] * stride_ak\n",
    "    w_ptrs = w_ptr + w_offs_k[:, None] * stride_wk + offs_bn[None, :] * stride_wn\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 初始化累加器\n",
    "    accumulator = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 主循环\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_K)):\n",
    "        # 加载激活值\n",
    "        a = tl.load(a_ptrs, mask=a_offs_k[None, :] < K - k * BLOCK_K, other=0.0)\n",
    "        w_packed = tl.load(w_ptrs, mask=w_offs_k[:, None] < K/4 - k * BLOCK_K/4, other=0.0)\n",
    "        \n",
    "        # 加载并解压int4权重\n",
    "        w_packed = tl.load(w_ptrs, mask=w_offs_k[:, None] < K, other=0)\n",
    "\n",
    "        unpacked_3 = w_packed & 0b11\n",
    "        unpacked_2 = (w_packed >> 2) & 0b11\n",
    "        unpacked_1 = (w_packed >> 4) & 0b11\n",
    "        unpacked_0 = (w_packed >> 6) & 0b11\n",
    "\n",
    "        \n",
    "        # 反量化权重\n",
    "        w_float_0 = (unpacked_0.to(tl.float16) - 1) * scale\n",
    "        w_float_1 = (unpacked_1.to(tl.float16) - 1) * scale\n",
    "        w_float_2 = (unpacked_2.to(tl.float16) - 1) * scale\n",
    "        w_float_3 = (unpacked_3.to(tl.float16) - 1) * scale\n",
    "        \n",
    "        # 累加结果\n",
    "        accumulator += tl.dot(a.to(tl.float32), w_float_0.to(tl.float32))\n",
    "        accumulator += tl.dot(a.to(tl.float32), w_float_1.to(tl.float32))\n",
    "        accumulator += tl.dot(a.to(tl.float32), w_float_2.to(tl.float32))\n",
    "        accumulator += tl.dot(a.to(tl.float32), w_float_3.to(tl.float32))\n",
    "\n",
    "        # 更新指针\n",
    "        a_ptrs += BLOCK_K * stride_ak\n",
    "        w_ptrs += BLOCK_K * stride_wk\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    # 写回结果\n",
    "    offs_om = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
    "    offs_on = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
    "    out_ptrs = output_ptr + offs_om[:, None] * stride_om + offs_on[None, :] * stride_on\n",
    "    o_mask = (offs_om[:, None] < M) & (offs_on[None, :] < N)\n",
    "    tl.store(out_ptrs, accumulator, mask=o_mask)\n",
    "\n",
    "# 包装函数\n",
    "def wint2_gemm(activation, weight, scale):\n",
    "    \"\"\"\n",
    "    执行WINT2 GEMM运算\n",
    "    参数:\n",
    "        activation: 激活矩阵 (M, K)，float16类型\n",
    "        weight: 权重矩阵 (N, K)，int2类型（以uint8打包存储）\n",
    "    返回:\n",
    "        output: 输出矩阵 (M, N)，float32类型\n",
    "    \"\"\"\n",
    "    M, K = activation.shape\n",
    "    #N, K_ = weight.shape\n",
    "    #assert K == K_, f\"维度不匹配: activation.K={K} != weight.K={K_}\"\n",
    "    \n",
    "    # 输出分配\n",
    "    output = paddle.zeros((M, N), dtype='float32')\n",
    "    \n",
    "    # 计算 grid 和 block 大小\n",
    "    BLOCK_M = 16\n",
    "    BLOCK_N = 16\n",
    "    BLOCK_K = 32\n",
    "    W_BLOCK_K = 8\n",
    "    GROUP_SIZE_M = 8\n",
    "    \n",
    "    grid = lambda META: (\n",
    "        triton.cdiv(M, BLOCK_M) * triton.cdiv(N, BLOCK_N),\n",
    "    )\n",
    "    \n",
    "    wint2_gemm_kernel[grid](\n",
    "        activation, weight, output,\n",
    "        scale,\n",
    "        M, N, K,\n",
    "        activation.strides[0], activation.strides[1],\n",
    "        weight.strides[0], weight.strides[1],\n",
    "        output.strides[0], output.strides[1],\n",
    "        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K, W_BLOCK_K=W_BLOCK_K,\n",
    "        GROUP_SIZE_M=GROUP_SIZE_M,\n",
    "    )\n",
    "    \n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量:\n",
      "Tensor(shape=[2, 8], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[-0.40147418,  0.84105122, -1.44239163, -0.12111820,  0.57649255,\n",
      "          0.20772524,  0.45755649,  0.08082178],\n",
      "        [ 2.34299016,  0.00141706, -1.09204257, -0.13947889,  0.54678589,\n",
      "          2.05279350,  0.40679640, -0.35385308]])\n",
      "\n",
      "打包后的张量:\n",
      "Tensor(shape=[2, 2], dtype=uint8, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[33 , 153],\n",
      "        [209, 185]])\n",
      "量化scale: 0.7809967199961344\n",
      "\n",
      "重建的张量:\n",
      "Tensor(shape=[2, 8], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[-0.78099674,  0.78099674, -0.78099674,  0.        ,  0.78099674,\n",
      "          0.        ,  0.78099674,  0.        ],\n",
      "        [ 1.56199348,  0.        , -0.78099674,  0.        ,  0.78099674,\n",
      "          1.56199348,  0.78099674,  0.        ]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "ZERO_POINT = 1\n",
    "def quantize_to_int2(tensor, scale=None):\n",
    "    if scale is None:\n",
    "        # 计算量化scale，使用绝对值最大值除以(2^2-1)=3\n",
    "        scale = float(paddle.max(paddle.abs(tensor)).item() / 3)\n",
    "    # 确保scale不为0\n",
    "    scale = max(scale, 1e-8)\n",
    "    # 量化到0-3范围\n",
    "    quant = paddle.clip(paddle.round(tensor / scale) + ZERO_POINT, 0, 3).astype('uint8')\n",
    "    # 重塑张量以准备打包\n",
    "    new_shape = list(quant.shape[:-1]) + [-1, 4]\n",
    "    quant = quant.reshape(new_shape)\n",
    "    # 打包4个int2值到一个int8\n",
    "    quant_np = quant.numpy()\n",
    "    packed = (quant_np[..., 0] << 6) | \\\n",
    "             (quant_np[..., 1] << 4) | \\\n",
    "             (quant_np[..., 2] << 2) | \\\n",
    "             quant_np[..., 3]\n",
    "    packed = paddle.to_tensor(packed, dtype='uint8')\n",
    "    \n",
    "    return packed, scale\n",
    "\n",
    "def dequantize_from_int2(packed, scale, original_shape):\n",
    "    # 解包int2值\n",
    "    packed_np = packed.numpy()\n",
    "    unpacked_3 = packed_np & 0b11\n",
    "    unpacked_2 = (packed_np >> 2) & 0b11\n",
    "    unpacked_1 = (packed_np >> 4) & 0b11\n",
    "    unpacked_0 = (packed_np >> 6) & 0b11\n",
    "    # 堆叠解包的值\n",
    "    unpacked = paddle.stack([paddle.to_tensor(unpacked_0), paddle.to_tensor(unpacked_1), paddle.to_tensor(unpacked_2), paddle.to_tensor(unpacked_3)], axis=-1)\n",
    "    # 重塑为原始形状\n",
    "    unpacked = unpacked.reshape(original_shape[:-1] + [-1])\n",
    "    # 反量化\n",
    "    tensor = (unpacked.astype('float32')- ZERO_POINT) * scale\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# 创建测试张量\n",
    "x = paddle.randn([2, 8], dtype='float32')\n",
    "print(\"原始张量:\")\n",
    "print(x)\n",
    "\n",
    "# 量化\n",
    "packed, scale = quantize_to_int2(x)\n",
    "print(\"\\n打包后的张量:\")\n",
    "print(packed)\n",
    "print(\"量化scale:\", scale)\n",
    "\n",
    "# 反量化\n",
    "reconstructed = dequantize_from_int2(packed, scale, x.shape)\n",
    "print(\"\\n重建的张量:\")\n",
    "print(reconstructed)\n",
    "\n",
    "# # 计算误差\n",
    "# error = paddle.abs(x - reconstructed)\n",
    "# print(\"\\n最大绝对误差:\", paddle.max(error).item())\n",
    "# print(\"平均绝对误差:\", paddle.mean(error).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompilationError",
     "evalue": "at 79:61:        unpacked_1 = (w_packed >> 4) & 0b11\n        unpacked_0 = (w_packed >> 6) & 0b11\n\n\n        # 反量化权重\n        w_float_0 = (unpacked_0.to(tl.float16) - 1) * scale\n        w_float_1 = (unpacked_1.to(tl.float16) - 1) * scale\n        w_float_2 = (unpacked_0.to(tl.float16) - 1) * scale\n        w_float_3 = (unpacked_1.to(tl.float16) - 1) * scale\n\n        # 累加结果\n        accumulator += tl.dot(a.to(tl.float32), w_float_0.to(tl.float32))\n                                                             ^\nAssertionError('First input shape ([constexpr[16], constexpr[32]]) and second input shape [constexpr[8], constexpr[16]] are not compatible for matmul (second index of first shape (32) must be equal to first index of second shape (8)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1124\u001b[0m, in \u001b[0;36mast_to_ttir\u001b[0;34m(fn, signature, specialization, constants, debug, arch)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     generator\u001b[39m.\u001b[39mvisit(fn\u001b[39m.\u001b[39mparse())\n\u001b[1;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m CompilationError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1017\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mvisit(node)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    417\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:293\u001b[0m, in \u001b[0;36mCodeGenerator.visit_Module\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Module\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m--> 293\u001b[0m     ast\u001b[39m.\u001b[39mNodeVisitor\u001b[39m.\u001b[39mgeneric_visit(\u001b[39mself\u001b[39m, node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:426\u001b[0m, in \u001b[0;36mNodeVisitor.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, AST):\n\u001b[0;32m--> 426\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(item)\n\u001b[1;32m    427\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, AST):\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1017\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mvisit(node)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    417\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:362\u001b[0m, in \u001b[0;36mCodeGenerator.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m# visit function body\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_compound_statement(node\u001b[39m.\u001b[39mbody)\n\u001b[1;32m    363\u001b[0m \u001b[39m# finalize function\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:288\u001b[0m, in \u001b[0;36mCodeGenerator.visit_compound_statement\u001b[0;34m(self, stmts)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mfor\u001b[39;00m stmt \u001b[39min\u001b[39;00m stmts:\n\u001b[0;32m--> 288\u001b[0m     ret_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(stmt)\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m ret_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(stmt, ast\u001b[39m.\u001b[39mReturn):\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1017\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mvisit(node)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    417\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:804\u001b[0m, in \u001b[0;36mCodeGenerator.visit_For\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscf_stack\u001b[39m.\u001b[39mappend(node)\n\u001b[0;32m--> 804\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_compound_statement(node\u001b[39m.\u001b[39mbody)\n\u001b[1;32m    805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscf_stack\u001b[39m.\u001b[39mpop()\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:288\u001b[0m, in \u001b[0;36mCodeGenerator.visit_compound_statement\u001b[0;34m(self, stmts)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mfor\u001b[39;00m stmt \u001b[39min\u001b[39;00m stmts:\n\u001b[0;32m--> 288\u001b[0m     ret_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(stmt)\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m ret_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(stmt, ast\u001b[39m.\u001b[39mReturn):\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1017\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mvisit(node)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    417\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:434\u001b[0m, in \u001b[0;36mCodeGenerator.visit_AugAssign\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    433\u001b[0m assign \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mAssign(targets\u001b[39m=\u001b[39m[node\u001b[39m.\u001b[39mtarget], value\u001b[39m=\u001b[39mrhs)\n\u001b[0;32m--> 434\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(assign)\n\u001b[1;32m    435\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdereference_name(name)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1017\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mvisit(node)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    417\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:414\u001b[0m, in \u001b[0;36mCodeGenerator.visit_Assign\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    413\u001b[0m names \u001b[39m=\u001b[39m _names[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 414\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mvalue)\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(names, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1017\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mvisit(node)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    417\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:463\u001b[0m, in \u001b[0;36mCodeGenerator.visit_BinOp\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    462\u001b[0m lhs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mleft)\n\u001b[0;32m--> 463\u001b[0m rhs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mright)\n\u001b[1;32m    464\u001b[0m method_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_method_name_for_bin_op\u001b[39m.\u001b[39mget(\u001b[39mtype\u001b[39m(node\u001b[39m.\u001b[39mop))\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[0m, in \u001b[0;36mCodeGenerator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     last_loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mget_loc()\n\u001b[0;32m-> 1017\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mvisit(node)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    417\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:946\u001b[0m, in \u001b[0;36mCodeGenerator.visit_Call\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    945\u001b[0m         extra_kwargs[\u001b[39m'\u001b[39m\u001b[39m_generator\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws)\n\u001b[1;32m    947\u001b[0m \u001b[39mif\u001b[39;00m fn \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_namespace\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/language/core.py:30\u001b[0m, in \u001b[0;36mbuiltin.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDid you forget to add @triton.jit ? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(`_builder` argument must be provided outside of JIT functions.)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[0;32m---> 30\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/language/core.py:972\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(input, other, allow_tf32, out_dtype, _builder)\u001b[0m\n\u001b[1;32m    971\u001b[0m out_dtype \u001b[39m=\u001b[39m _constexpr_to_value(out_dtype)\n\u001b[0;32m--> 972\u001b[0m \u001b[39mreturn\u001b[39;00m semantic\u001b[39m.\u001b[39mdot(\u001b[39minput\u001b[39m, other, allow_tf32, out_dtype, _builder)\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/language/semantic.py:1251\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, allow_tf32, out_dtype, builder)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(rhs\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSecond input shape (\u001b[39m\u001b[39m{\u001b[39;00mrhs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m) is not two dimensional!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1251\u001b[0m \u001b[39massert\u001b[39;00m lhs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m rhs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalue, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFirst input shape (\u001b[39m\u001b[39m{\u001b[39;00mlhs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m) and second input shape \u001b[39m\u001b[39m{\u001b[39;00mrhs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m are not compatible for matmul (second index of first shape (\u001b[39m\u001b[39m{\u001b[39;00mlhs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m) must be equal to first index of second shape (\u001b[39m\u001b[39m{\u001b[39;00mrhs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1252\u001b[0m \u001b[39massert\u001b[39;00m lhs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalue \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m16\u001b[39m \u001b[39mand\u001b[39;00m lhs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalue \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m16\u001b[39m \\\n\u001b[1;32m   1253\u001b[0m     \u001b[39mand\u001b[39;00m rhs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalue \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m16\u001b[39m,\\\n\u001b[1;32m   1254\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAll values in both first input shape (\u001b[39m\u001b[39m{\u001b[39;00mlhs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m) and second input shape (\u001b[39m\u001b[39m{\u001b[39;00mrhs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m) must be >= 16!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: First input shape ([constexpr[16], constexpr[32]]) and second input shape [constexpr[8], constexpr[16]] are not compatible for matmul (second index of first shape (32) must be equal to first index of second shape (8)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mCompilationError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/root/paddlejob/workspace/env_run/output/whs/triton.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m packed_weight, scale \u001b[39m=\u001b[39m quantize_to_int2(weight)\n\u001b[1;32m     <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# 使用WINT4 GEMM kernel计算结果\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m output \u001b[39m=\u001b[39m wint2_gemm(activation, packed_weight\u001b[39m.\u001b[39mT, scale)\n\u001b[1;32m     <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m dequant_weight \u001b[39m=\u001b[39m dequantize_from_int2(packed_weight, scale, weight\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# 使用反量化后的权重计算参考结果\u001b[39;00m\n",
      "\u001b[1;32m/root/paddlejob/workspace/env_run/output/whs/triton.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=122'>123</a>\u001b[0m GROUP_SIZE_M \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=124'>125</a>\u001b[0m grid \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m META: (\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m     triton\u001b[39m.\u001b[39mcdiv(M, BLOCK_M) \u001b[39m*\u001b[39m triton\u001b[39m.\u001b[39mcdiv(N, BLOCK_N),\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m wint2_gemm_kernel[grid](\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m     activation, weight, output,\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=130'>131</a>\u001b[0m     scale,\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m     M, N, K,\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m     activation\u001b[39m.\u001b[39mstrides[\u001b[39m0\u001b[39m], activation\u001b[39m.\u001b[39mstrides[\u001b[39m1\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m     weight\u001b[39m.\u001b[39mstrides[\u001b[39m0\u001b[39m], weight\u001b[39m.\u001b[39mstrides[\u001b[39m1\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m     output\u001b[39m.\u001b[39mstrides[\u001b[39m0\u001b[39m], output\u001b[39m.\u001b[39mstrides[\u001b[39m1\u001b[39m],\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=135'>136</a>\u001b[0m     BLOCK_M\u001b[39m=\u001b[39mBLOCK_M, BLOCK_N\u001b[39m=\u001b[39mBLOCK_N, BLOCK_K\u001b[39m=\u001b[39mBLOCK_K, W_BLOCK_K\u001b[39m=\u001b[39mW_BLOCK_K,\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m     GROUP_SIZE_M\u001b[39m=\u001b[39mGROUP_SIZE_M,\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://icoding.baidu-int.com:443/root/paddlejob/workspace/env_run/output/whs/triton.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m<string>:63\u001b[0m, in \u001b[0;36mwint2_gemm_kernel\u001b[0;34m(a_ptr, w_ptr, output_ptr, scale, M, N, K, stride_am, stride_ak, stride_wk, stride_wn, stride_om, stride_on, BLOCK_M, BLOCK_N, BLOCK_K, W_BLOCK_K, GROUP_SIZE_M, grid, num_warps, num_stages, extern_libs, stream, warmup, device, device_type)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/compiler.py:476\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(fn, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m path \u001b[39m=\u001b[39m metadata_group\u001b[39m.\u001b[39mget(ir_filename)\n\u001b[1;32m    475\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m     next_module \u001b[39m=\u001b[39m compile_kernel(module)\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m ir \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mamdgcn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    478\u001b[0m         extra_file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.hsaco_path\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/compiler.py:381\u001b[0m, in \u001b[0;36mcompile.<locals>.<lambda>\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m    378\u001b[0m stages \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    379\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mast\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: fn, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    380\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mttir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: parse_mlir_module(path, context),\n\u001b[0;32m--> 381\u001b[0m                   \u001b[39mlambda\u001b[39;00m src: optimize_ttir(ast_to_ttir(src, signature, configs[\u001b[39m0\u001b[39m], constants, debug\u001b[39m=\u001b[39mdebug, arch\u001b[39m=\u001b[39march), arch))\n\u001b[1;32m    382\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mttgir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: parse_mlir_module(path, context),\n\u001b[1;32m    383\u001b[0m                    \u001b[39mlambda\u001b[39;00m src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, arch))\n\u001b[1;32m    384\u001b[0m stages[\u001b[39m\"\u001b[39m\u001b[39mllir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mlambda\u001b[39;00m path: Path(path)\u001b[39m.\u001b[39mread_text(),\n\u001b[1;32m    385\u001b[0m                   \u001b[39mlambda\u001b[39;00m src: ttgir_to_llir(src, extern_libs, arch))\n",
      "File \u001b[0;32m~/anaconda3/envs/whs/lib/python3.11/site-packages/triton/compiler/code_generator.py:1133\u001b[0m, in \u001b[0;36mast_to_ttir\u001b[0;34m(fn, signature, specialization, constants, debug, arch)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mif\u001b[39;00m node \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m     \u001b[39mraise\u001b[39;00m CompilationError(fn\u001b[39m.\u001b[39msrc, node, \u001b[39mrepr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m ret \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39mmodule\n\u001b[1;32m   1135\u001b[0m \u001b[39m# module takes ownership of the context\u001b[39;00m\n",
      "\u001b[0;31mCompilationError\u001b[0m: at 79:61:        unpacked_1 = (w_packed >> 4) & 0b11\n        unpacked_0 = (w_packed >> 6) & 0b11\n\n\n        # 反量化权重\n        w_float_0 = (unpacked_0.to(tl.float16) - 1) * scale\n        w_float_1 = (unpacked_1.to(tl.float16) - 1) * scale\n        w_float_2 = (unpacked_0.to(tl.float16) - 1) * scale\n        w_float_3 = (unpacked_1.to(tl.float16) - 1) * scale\n\n        # 累加结果\n        accumulator += tl.dot(a.to(tl.float32), w_float_0.to(tl.float32))\n                                                             ^\nAssertionError('First input shape ([constexpr[16], constexpr[32]]) and second input shape [constexpr[8], constexpr[16]] are not compatible for matmul (second index of first shape (32) must be equal to first index of second shape (8)')"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子以保证结果可复现\n",
    "paddle.seed(4)\n",
    "np.random.seed(4)\n",
    "\n",
    "# 创建示例数据\n",
    "M, N, K = 128, 64, 32\n",
    "\n",
    "# 创建激活矩阵 (M, K)\n",
    "activation = paddle.randn([M, K], dtype='float32')\n",
    "\n",
    "# 创建权重矩阵 (N, K)\n",
    "weight = paddle.randn([N, K])\n",
    "\n",
    "# 量化权重到int2\n",
    "packed_weight, scale = quantize_to_int2(weight)\n",
    "\n",
    "\n",
    "# 使用WINT4 GEMM kernel计算结果\n",
    "output = wint2_gemm(activation, packed_weight.T, scale)\n",
    "\n",
    "dequant_weight = dequantize_from_int2(packed_weight, scale, weight.shape)\n",
    "# 使用反量化后的权重计算参考结果\n",
    "ref_output = paddle.matmul(activation.astype('float32'), \n",
    "                            dequant_weight.T.astype('float32'))\n",
    "\n",
    "# 计算相对误差\n",
    "rel_error = paddle.abs(output - ref_output) / (paddle.abs(ref_output) + 1e-7)\n",
    "max_rel_error = paddle.max(rel_error)\n",
    "avg_rel_error = paddle.mean(rel_error)\n",
    "\n",
    "print(f\"最大相对误差: {max_rel_error.item():.6f}\")\n",
    "print(f\"平均相对误差: {avg_rel_error.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量:\n",
      "Tensor(shape=[2, 8], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[-1.37485266,  0.25441313,  0.23476355,  0.57191873, -1.08756435,\n",
      "         -0.89395362, -1.17351019,  0.37844741],\n",
      "        [ 1.74194264,  0.32449320,  1.28417206, -1.27401042,  1.71044135,\n",
      "          0.39335835, -0.70837349,  0.77900213]])\n",
      "\n",
      "打包后的张量:\n",
      "Tensor(shape=[2, 2], dtype=uint8, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[22 , 2  ],\n",
      "        [236, 226]])\n",
      "量化scale: 0.5806475480397543\n",
      "\n",
      "重建的张量:\n",
      "Tensor(shape=[2, 8], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[-0.58064753,  0.        ,  0.        ,  0.58064753, -0.58064753,\n",
      "         -0.58064753, -0.58064753,  0.58064753],\n",
      "        [ 1.16129506,  0.58064753,  1.16129506, -0.58064753,  1.16129506,\n",
      "          0.58064753, -0.58064753,  0.58064753]])\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "ZERO_POINT = 1\n",
    "def quantize_to_int2(tensor, scale=None):\n",
    "    if scale is None:\n",
    "        # 计算量化scale，使用绝对值最大值除以(2^2-1)=3\n",
    "        scale = float(paddle.max(paddle.abs(tensor)).item() / 3)\n",
    "    # 确保scale不为0\n",
    "    scale = max(scale, 1e-8)\n",
    "    # 量化到0-3范围\n",
    "    quant = paddle.clip(paddle.round(tensor / scale) + ZERO_POINT, 0, 3).astype('uint8')\n",
    "    # 重塑张量以准备打包\n",
    "    new_shape = list(quant.shape[:-1]) + [-1, 4]\n",
    "    quant = quant.reshape(new_shape)\n",
    "    # 打包4个int2值到一个int8\n",
    "    quant_np = quant.numpy()\n",
    "    packed = (quant_np[..., 0] << 6) | \\\n",
    "             (quant_np[..., 1] << 4) | \\\n",
    "             (quant_np[..., 2] << 2) | \\\n",
    "             quant_np[..., 3]\n",
    "    packed = paddle.to_tensor(packed, dtype='uint8')\n",
    "    \n",
    "    return packed, scale\n",
    "\n",
    "def dequantize_from_int2(packed, scale, original_shape):\n",
    "    # 解包int2值\n",
    "    packed_np = packed.numpy()\n",
    "    unpacked_3 = packed_np & 0b11\n",
    "    unpacked_2 = (packed_np >> 2) & 0b11\n",
    "    unpacked_1 = (packed_np >> 4) & 0b11\n",
    "    unpacked_0 = (packed_np >> 6) & 0b11\n",
    "    # 堆叠解包的值\n",
    "    unpacked = paddle.stack([paddle.to_tensor(unpacked_0), paddle.to_tensor(unpacked_1), paddle.to_tensor(unpacked_2), paddle.to_tensor(unpacked_3)], axis=-1)\n",
    "    # 重塑为原始形状\n",
    "    unpacked = unpacked.reshape(original_shape[:-1] + [-1])\n",
    "    # 反量化\n",
    "    tensor = (unpacked.astype('float32')- ZERO_POINT) * scale\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# 创建测试张量\n",
    "x = paddle.randn([2, 8], dtype='float32')\n",
    "print(\"原始张量:\")\n",
    "print(x)\n",
    "\n",
    "# 量化\n",
    "packed, scale = quantize_to_int2(x)\n",
    "print(\"\\n打包后的张量:\")\n",
    "print(packed)\n",
    "print(\"量化scale:\", scale)\n",
    "\n",
    "# 反量化\n",
    "reconstructed = dequantize_from_int2(packed, scale, x.shape)\n",
    "print(\"\\n重建的张量:\")\n",
    "print(reconstructed)\n",
    "\n",
    "# # 计算误差\n",
    "# error = paddle.abs(x - reconstructed)\n",
    "# print(\"\\n最大绝对误差:\", paddle.max(error).item())\n",
    "# print(\"平均绝对误差:\", paddle.mean(error).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
